W0919 16:23:13.981000 227810 site-packages/torch/distributed/run.py:793] 
W0919 16:23:13.981000 227810 site-packages/torch/distributed/run.py:793] *****************************************
W0919 16:23:13.981000 227810 site-packages/torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0919 16:23:13.981000 227810 site-packages/torch/distributed/run.py:793] *****************************************
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:01<00:04,  1.52s/it]Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:01<00:05,  1.75s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.70s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.80s/it]Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.77s/it]Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.81s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.30s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.44s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.26s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.46s/it]
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
The new lm_head weights will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
The new lm_head weights will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
wandb: Currently logged in as: luke0112. Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.2
wandb: Run data is saved locally in /data2/jeongseokoh/jeongseokoh/LatentCOMP_cleaned/wandb/run-20250919_162420-rzx1s11c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run LoPA_Llama3.1_8B_8_Lowers_assistant_20Specials
wandb: â­ï¸ View project at https://wandb.ai/luke0112/latentcomp-cleaned
wandb: ðŸš€ View run at https://wandb.ai/luke0112/latentcomp-cleaned/runs/rzx1s11c
Epoch 1 [train]:   0%|          | 0/4470 [00:00<?, ?it/s]Epoch 1 [train]:   0%|          | 1/4470 [00:11<14:09:25, 11.40s/it]Epoch 1 [train]:   0%|          | 2/4470 [00:22<13:57:13, 11.24s/it]Epoch 1 [train]:   0%|          | 3/4470 [00:33<13:54:22, 11.21s/it]Epoch 1 [train]:   0%|          | 4/4470 [00:44<13:50:57, 11.16s/it]Epoch 1 [train]:   0%|          | 5/4470 [00:55<13:40:47, 11.03s/it]Epoch 1 [train]:   0%|          | 6/4470 [01:06<13:44:04, 11.08s/it]Epoch 1 [train]:   0%|          | 7/4470 [01:17<13:40:36, 11.03s/it]Epoch 1 [train]:   0%|          | 8/4470 [01:28<13:45:07, 11.10s/it]Epoch 1 [train]:   0%|          | 9/4470 [01:40<13:45:46, 11.11s/it]Epoch 1 [train]:   0%|          | 10/4470 [01:50<13:41:36, 11.05s/it]Epoch 1 [train]:   0%|          | 11/4470 [02:01<13:32:27, 10.93s/it]Epoch 1 [train]:   0%|          | 12/4470 [02:12<13:34:29, 10.96s/it]Epoch 1 [train]:   0%|          | 13/4470 [02:23<13:38:22, 11.02s/it]Epoch 1 [train]:   0%|          | 14/4470 [02:34<13:36:21, 10.99s/it]Epoch 1 [train]:   0%|          | 15/4470 [02:45<13:41:17, 11.06s/it]Epoch 1 [train]:   0%|          | 16/4470 [02:56<13:38:03, 11.02s/it]Epoch 1 [train]:   0%|          | 17/4470 [03:07<13:31:10, 10.93s/it]Epoch 1 [train]:   0%|          | 18/4470 [03:18<13:33:09, 10.96s/it]Epoch 1 [train]:   0%|          | 19/4470 [03:29<13:30:14, 10.92s/it]Epoch 1 [train]:   0%|          | 20/4470 [03:40<13:29:27, 10.91s/it]Epoch 1 [train]:   0%|          | 21/4470 [03:51<13:30:03, 10.92s/it]Epoch 1 [train]:   0%|          | 22/4470 [04:02<13:27:03, 10.89s/it]Epoch 1 [train]:   1%|          | 23/4470 [04:13<13:28:35, 10.91s/it]Epoch 1 [train]:   1%|          | 24/4470 [04:24<13:29:06, 10.92s/it]Epoch 1 [train]:   1%|          | 25/4470 [04:34<13:27:57, 10.91s/it]Epoch 1 [train]:   1%|          | 26/4470 [04:45<13:30:39, 10.94s/it]Epoch 1 [train]:   1%|          | 27/4470 [04:56<13:30:56, 10.95s/it]Epoch 1 [train]:   1%|          | 28/4470 [05:07<13:28:09, 10.92s/it]Epoch 1 [train]:   1%|          | 29/4470 [05:18<13:26:21, 10.89s/it]Epoch 1 [train]:   1%|          | 30/4470 [05:29<13:26:57, 10.90s/it]Epoch 1 [train]:   1%|          | 31/4470 [05:40<13:28:11, 10.92s/it]Epoch 1 [train]:   1%|          | 32/4470 [05:51<13:30:59, 10.96s/it]Epoch 1 [train]:   1%|          | 33/4470 [06:02<13:32:39, 10.99s/it]Epoch 1 [train]:   1%|          | 34/4470 [06:13<13:30:22, 10.96s/it]Epoch 1 [train]:   1%|          | 35/4470 [06:24<13:29:23, 10.95s/it]Epoch 1 [train]:   1%|          | 36/4470 [06:35<13:28:35, 10.94s/it]Epoch 1 [train]:   1%|          | 37/4470 [06:46<13:28:52, 10.95s/it]Epoch 1 [train]:   1%|          | 38/4470 [06:57<13:27:25, 10.93s/it]Epoch 1 [train]:   1%|          | 39/4470 [07:08<13:24:49, 10.90s/it]Epoch 1 [train]:   1%|          | 40/4470 [07:19<13:27:09, 10.93s/it]Epoch 1 [train]:   1%|          | 41/4470 [07:29<13:25:15, 10.91s/it]Epoch 1 [train]:   1%|          | 42/4470 [07:40<13:26:30, 10.93s/it]Epoch 1 [train]:   1%|          | 43/4470 [07:51<13:25:48, 10.92s/it]Epoch 1 [train]:   1%|          | 44/4470 [08:02<13:19:22, 10.84s/it]Epoch 1 [train]:   1%|          | 45/4470 [08:13<13:24:05, 10.90s/it]Epoch 1 [train]:   1%|          | 46/4470 [08:24<13:25:01, 10.92s/it]Epoch 1 [train]:   1%|          | 47/4470 [08:35<13:26:49, 10.95s/it]Epoch 1 [train]:   1%|          | 48/4470 [08:46<13:28:32, 10.97s/it]Epoch 1 [train]:   1%|          | 49/4470 [08:57<13:22:24, 10.89s/it]Epoch 1 [train]:   1%|          | 50/4470 [09:08<13:23:28, 10.91s/it]Epoch 1 [train]:   1%|          | 51/4470 [09:19<13:25:22, 10.94s/it]Epoch 1 [train]:   1%|          | 52/4470 [09:29<13:24:24, 10.92s/it]Epoch 1 [train]:   1%|          | 53/4470 [09:40<13:26:03, 10.95s/it]Epoch 1 [train]:   1%|          | 54/4470 [09:51<13:25:08, 10.94s/it]Epoch 1 [train]:   1%|          | 55/4470 [10:02<13:23:46, 10.92s/it]Epoch 1 [train]:   1%|â–         | 56/4470 [10:13<13:26:06, 10.96s/it]Epoch 1 [train]:   1%|â–         | 57/4470 [10:24<13:24:55, 10.94s/it]Epoch 1 [train]:   1%|â–         | 58/4470 [10:35<13:20:14, 10.88s/it]Epoch 1 [train]:   1%|â–         | 59/4470 [10:46<13:19:24, 10.87s/it]Epoch 1 [train]:   1%|â–         | 60/4470 [10:57<13:23:47, 10.94s/it]Epoch 1 [train]:   1%|â–         | 61/4470 [11:08<13:24:06, 10.94s/it]Epoch 1 [train]:   1%|â–         | 62/4470 [11:19<13:23:51, 10.94s/it]Epoch 1 [train]:   1%|â–         | 63/4470 [11:30<13:26:32, 10.98s/it]Epoch 1 [train]:   1%|â–         | 64/4470 [11:41<13:27:32, 11.00s/it]Epoch 1 [train]:   1%|â–         | 65/4470 [11:52<13:30:09, 11.04s/it]Epoch 1 [train]:   1%|â–         | 66/4470 [12:03<13:31:07, 11.05s/it]Epoch 1 [train]:   1%|â–         | 67/4470 [12:14<13:25:53, 10.98s/it]Epoch 1 [train]:   2%|â–         | 68/4470 [12:25<13:24:20, 10.96s/it]Epoch 1 [train]:   2%|â–         | 69/4470 [12:36<13:26:46, 11.00s/it]Epoch 1 [train]:   2%|â–         | 70/4470 [12:47<13:26:17, 10.99s/it]Epoch 1 [train]:   2%|â–         | 71/4470 [12:58<13:20:37, 10.92s/it]Epoch 1 [train]:   2%|â–         | 72/4470 [13:09<13:23:40, 10.96s/it]Epoch 1 [train]:   2%|â–         | 73/4470 [13:20<13:20:48, 10.93s/it]Epoch 1 [train]:   2%|â–         | 74/4470 [13:31<13:21:02, 10.93s/it]Epoch 1 [train]:   2%|â–         | 75/4470 [13:42<13:21:41, 10.94s/it]Epoch 1 [train]:   2%|â–         | 76/4470 [13:53<13:23:12, 10.97s/it]Epoch 1 [train]:   2%|â–         | 77/4470 [14:03<13:19:34, 10.92s/it]Epoch 1 [train]:   2%|â–         | 78/4470 [14:14<13:23:34, 10.98s/it]Epoch 1 [train]:   2%|â–         | 79/4470 [14:25<13:21:13, 10.95s/it]Epoch 1 [train]:   2%|â–         | 80/4470 [14:36<13:19:06, 10.92s/it]Epoch 1 [train]:   2%|â–         | 81/4470 [14:47<13:14:45, 10.86s/it]Epoch 1 [train]:   2%|â–         | 82/4470 [14:58<13:15:18, 10.87s/it]Epoch 1 [train]:   2%|â–         | 83/4470 [15:09<13:20:21, 10.95s/it]Epoch 1 [train]:   2%|â–         | 84/4470 [15:20<13:17:33, 10.91s/it]Epoch 1 [train]:   2%|â–         | 85/4470 [15:30<13:09:44, 10.81s/it]Epoch 1 [train]:   2%|â–         | 86/4470 [15:41<13:11:07, 10.83s/it]Epoch 1 [tra