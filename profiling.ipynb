{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afb85d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda | dtype: torch.bfloat16\n"
     ]
    }
   ],
   "source": [
    "# ==== 설정 (환경에 맞게 수정) ====\n",
    "VANILLA_REPO_ID     = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"       # 바닐라 모델\n",
    "TRI_REPO_ID         = \"jeongseokoh/LoPA_Llama3.1_8B_8_Lowers\"       # 너의 LoPA TRI 레포\n",
    "BASE_SUBFOLDER      = \"base\"                                        # TRI 레포의 base 가중치 폴더\n",
    "LORA_SUBFOLDER      = \"lora\"                                        # LoRA 폴더(없으면 자동 건너뜀)\n",
    "LOPA_MODELING_PATH  = \"./lopa_llama_modeling.py\"                    # (완성본) TRI 모델링 파일 경로\n",
    "TOKENIZER_PATH      = TRI_REPO_ID                                   # 동일 토크나이저 권장\n",
    "ATTN_IMPL           = \"flash_attention_2\"                           # \"flash_attention_2\" | \"eager\" | \"sdpa\"\n",
    "HF_TOKEN            = None  # private면 토큰 넣어줘\n",
    "LOWER_K = 8\n",
    "# 길이 (요청 조건)\n",
    "LEN_S   = 256   # system\n",
    "LEN_U   = 256   # user(질의)\n",
    "LEN_D   = 10240  # document\n",
    "LEN_H   = 4     # assistant header 길이(고정 더미)\n",
    "LEN_GEN = 512   # 생성 토큰 수\n",
    "\n",
    "# 실행 환경 권장 변수\n",
    "import os, torch, sys\n",
    "os.environ.setdefault(\"TOKENIZERS_PARALLELISM\", \"false\")\n",
    "os.environ.setdefault(\"CUDA_DEVICE_MAX_CONNECTIONS\", \"1\")\n",
    "os.environ.setdefault(\"PYTORCH_CUDA_ALLOC_CONF\", \"max_split_size_mb:128,expandable_segments:True\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype  = (torch.bfloat16 if (torch.cuda.is_available() and torch.cuda.is_bf16_supported())\n",
    "          else (torch.float16 if torch.cuda.is_available() else torch.float32))\n",
    "print(\"device:\", device, \"| dtype:\", dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "340e30e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df8011c64e214c0e813b07db75c8bbbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] TRI patch loaded: ./lopa_llama_modeling.py\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2cc34ed5afe40169dfd6385474d3ef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] LoRA adapters loaded: jeongseokoh/LoPA_Llama3.1_8B_8_Lowers/lora\n",
      "[OK] models ready\n"
     ]
    }
   ],
   "source": [
    "# ==== 토크나이저 ====\n",
    "from transformers import AutoTokenizer\n",
    "tok = AutoTokenizer.from_pretrained(TOKENIZER_PATH, use_fast=True, token=HF_TOKEN)\n",
    "if tok.pad_token is None:\n",
    "    tok.pad_token = tok.eos_token\n",
    "\n",
    "# ==== 바닐라 모델 ====\n",
    "from transformers import AutoModelForCausalLM\n",
    "van_model = AutoModelForCausalLM.from_pretrained(\n",
    "    VANILLA_REPO_ID, torch_dtype=dtype, token=HF_TOKEN\n",
    ").to(device)\n",
    "van_model.eval()\n",
    "\n",
    "# ==== TRI 모델링을 transformers 내부에 주입 ====\n",
    "import importlib.util, transformers, transformers.models.llama as llama_pkg\n",
    "target_name = \"transformers.models.llama.modeling_llama\"\n",
    "spec = importlib.util.spec_from_file_location(target_name, LOPA_MODELING_PATH)\n",
    "mod = importlib.util.module_from_spec(spec)\n",
    "sys.modules.pop(target_name, None)\n",
    "sys.modules[target_name] = mod\n",
    "spec.loader.exec_module(mod)\n",
    "setattr(llama_pkg, \"modeling_llama\", mod)\n",
    "from transformers.models.llama.modeling_llama import LlamaForCausalLM  # (패치된) 클래스\n",
    "print(\"[DEBUG] TRI patch loaded:\", LOPA_MODELING_PATH)\n",
    "\n",
    "# ==== TRI 모델 ====\n",
    "tri_model = LlamaForCausalLM.from_pretrained(\n",
    "    TRI_REPO_ID, subfolder=BASE_SUBFOLDER, torch_dtype=dtype, token=HF_TOKEN\n",
    ").to(device)\n",
    "\n",
    "# LoRA 어댑터(있으면 자동 로드)\n",
    "try:\n",
    "    from peft import PeftModel\n",
    "    tri_model = PeftModel.from_pretrained(tri_model, TRI_REPO_ID, subfolder=LORA_SUBFOLDER, token=HF_TOKEN)\n",
    "    tri_model = tri_model.to(device)\n",
    "    print(f\"[info] LoRA adapters loaded: {TRI_REPO_ID}/{LORA_SUBFOLDER}\")\n",
    "except Exception as e:\n",
    "    print(\"[info] LoRA not found or skipped:\", str(e).split(\"\\n\")[0])\n",
    "\n",
    "# 어텐션 백엔드 지정(둘 다)\n",
    "for m in (van_model, tri_model):\n",
    "    try:\n",
    "        m.config._attn_implementation = ATTN_IMPL\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# 추론모드 & TF32\n",
    "torch.set_grad_enabled(False)\n",
    "try:\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# TRI API 존재 확인\n",
    "for need in (\"tri_build_caches\", \"tri_forward_assistant\", \"tri_step_logits\"):\n",
    "    assert hasattr(tri_model, need), f\"Missing TRI API: {need}\"\n",
    "\n",
    "van_model.eval(); tri_model.eval()\n",
    "print(\"[OK] models ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "229c8552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lens: 256 10496 4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# \"한 글자 → 1토큰\" 되는 후보를 찾아서 filler 토큰으로 사용\n",
    "def pick_single_token_id(candidates=(\"A\", \"B\", \"C\", \"x\", \"y\", \"z\")):\n",
    "    for s in candidates:\n",
    "        ids = tok.encode(s, add_special_tokens=False)\n",
    "        if len(ids) == 1 and ids[0] != tok.eos_token_id:\n",
    "            return ids[0]\n",
    "    # fallback: vocab 중앙값\n",
    "    return min(len(tok), 32_000) - 10\n",
    "\n",
    "FILL_ID = pick_single_token_id()\n",
    "HEAD_ID = pick_single_token_id((\"?\", \":\", \".\", \"!\"))\n",
    "\n",
    "def make_ids(length: int, fill_id: int = FILL_ID):\n",
    "    return torch.full((1, length), fill_id, dtype=torch.long, device=device)\n",
    "\n",
    "def build_segments_lengths():\n",
    "    S_ids  = make_ids(LEN_S,  FILL_ID)\n",
    "    U_ids  = make_ids(LEN_U,  FILL_ID)\n",
    "    D_ids  = make_ids(LEN_D,  FILL_ID)\n",
    "    H_ids  = make_ids(LEN_H,  HEAD_ID)\n",
    "    # LoPA user 프리필 = Document + User\n",
    "    U_total = torch.cat([D_ids, U_ids], dim=1)  # 1 x (1024+256)\n",
    "    return S_ids, U_total, H_ids\n",
    "\n",
    "S_ids, Utotal_ids, H_ids = build_segments_lengths()\n",
    "print(\"lens:\", S_ids.size(1), Utotal_ids.size(1), H_ids.size(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6113d5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== FLOPs 계산 (Attention-only) ====\n",
    "# 가정:\n",
    "#  - 어텐션 FLOPs ≈ 4 * (#heads) * head_dim * (Tq * Tk)     (QKᵀ + AV 두 matmul)\n",
    "#  - Prefill에서 한 번에 블록 길이 N을 넣으면 per-layer FLOPs ≈ 4 * H * Dh * N^2\n",
    "#  - Generation(단일 토큰 루프) per-layer FLOPs ≈ 4 * H * Dh * sum_i Tk_i\n",
    "#  - TRI: Prefill은 Upper: (S+H)^2, Lower: (S+U+H)^2 (Header 포함)\n",
    "#         Generation에서 Upper: Tk_i = S+H+(i-1), Lower: Tk_i = S+U+H+(i-1)\n",
    "\n",
    "def _attn_cfg(model):\n",
    "    cfg = model.config\n",
    "    H = int(cfg.num_attention_heads)\n",
    "    Dh = getattr(cfg, \"head_dim\", cfg.hidden_size // H)\n",
    "    L = int(cfg.num_hidden_layers)\n",
    "    return L, H, Dh\n",
    "\n",
    "def flops_vanilla_attention(model, S:int, U:int, Htok:int, A:int):\n",
    "    L, Hh, Dh = _attn_cfg(model)\n",
    "    N = S + U + Htok\n",
    "    # Prefill: per-layer 4*H*Dh*N^2\n",
    "    pre_per_layer = 4.0 * Hh * Dh * (N**2)\n",
    "    # Gen: sum Tk = A*N + A*(A-1)/2\n",
    "    sum_Tk = A * N + (A * (A - 1)) / 2.0\n",
    "    gen_per_layer = 4.0 * Hh * Dh * sum_Tk\n",
    "    pre = pre_per_layer * L\n",
    "    gen = gen_per_layer * L\n",
    "    tot = pre + gen\n",
    "    return pre, gen, tot\n",
    "\n",
    "def flops_tri_attention(model, S:int, U:int, Htok:int, A:int, K:int):\n",
    "    L, Hh, Dh = _attn_cfg(model)\n",
    "    K = int(K)\n",
    "    # Prefill:\n",
    "    #  Lower K layers: (S+U+H)^2, Upper L-K layers: (S+H)^2\n",
    "    N_lower = S + U + Htok\n",
    "    N_upper = S + Htok\n",
    "    pre_lower = 4.0 * Hh * Dh * (N_lower**2) * K\n",
    "    pre_upper = 4.0 * Hh * Dh * (N_upper**2) * (L - K)\n",
    "    pre = pre_lower + pre_upper\n",
    "    # Generation:\n",
    "    #  sum Tk lower = A*(S+U+H) + A(A-1)/2\n",
    "    #  sum Tk upper = A*(S+H)   + A(A-1)/2\n",
    "    sumTk_lower = A * (S + U + Htok) + (A * (A - 1)) / 2.0\n",
    "    sumTk_upper = A * (S + Htok)     + (A * (A - 1)) / 2.0\n",
    "    gen_lower = 4.0 * Hh * Dh * sumTk_lower * K\n",
    "    gen_upper = 4.0 * Hh * Dh * sumTk_upper * (L - K)\n",
    "    gen = gen_lower + gen_upper\n",
    "    tot = pre + gen\n",
    "    return pre, gen, tot\n",
    "\n",
    "def to_gflops(x):   # FLOPs → GFLOPs\n",
    "    return x / 1e9\n",
    "\n",
    "def throughput_gflops_per_s(gflops, seconds):\n",
    "    return (gflops / max(1e-9, seconds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8fa7203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def sync():\n",
    "    if device.type == \"cuda\":\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "def reset_peak():\n",
    "    if device.type == \"cuda\":\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "def get_mem_mib():\n",
    "    if device.type != \"cuda\": \n",
    "        return {\"alloc_MiB\": 0.0, \"reserved_MiB\": 0.0}\n",
    "    alloc = torch.cuda.max_memory_allocated() / (1024**2)\n",
    "    reserv= torch.cuda.max_memory_reserved() / (1024**2)\n",
    "    return {\"alloc_MiB\": round(alloc,2), \"reserved_MiB\": round(reserv,2)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "738d9009",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "@torch.inference_mode()\n",
    "def profile_vanilla(model, S_ids, Utotal_ids, H_ids, gen_len, greedily=True):\n",
    "    S = int(S_ids.size(1)); U = int(Utotal_ids.size(1)); Htok = int(H_ids.size(1)); A = int(gen_len)\n",
    "    prompt = torch.cat([S_ids, Utotal_ids, H_ids], dim=1)\n",
    "    L_prompt = prompt.size(1)\n",
    "\n",
    "    # FLOPs 이론값(어텐션 기준)\n",
    "    FLOP_pre, FLOP_gen, FLOP_tot = flops_vanilla_attention(model, S, U, Htok, A)\n",
    "\n",
    "    reset_peak(); sync(); t0 = time.perf_counter()\n",
    "    out = model(input_ids=prompt, use_cache=True)\n",
    "    sync(); t_prefill = time.perf_counter() - t0\n",
    "\n",
    "    logits = out.logits[:, -1, :]\n",
    "    if greedily:\n",
    "        next_id = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "    else:\n",
    "        probs = F.softmax(logits, dim=-1); next_id = torch.multinomial(probs, num_samples=1)\n",
    "    pkv = out.past_key_values\n",
    "\n",
    "    sync(); t1 = time.perf_counter()\n",
    "    out = model(input_ids=next_id, past_key_values=pkv, use_cache=True)\n",
    "    sync(); t_first = time.perf_counter() - t1\n",
    "\n",
    "    cur = next_id; pkv = out.past_key_values\n",
    "    sync(); tg0 = time.perf_counter()\n",
    "    for _ in range(gen_len - 1):\n",
    "        out = model(input_ids=cur, past_key_values=pkv, use_cache=True)\n",
    "        logits = out.logits[:, -1, :]\n",
    "        if greedily:\n",
    "            cur = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "        else:\n",
    "            probs = F.softmax(logits, dim=-1); cur = torch.multinomial(probs, num_samples=1)\n",
    "        pkv = out.past_key_values\n",
    "    sync(); t_gen = time.perf_counter() - tg0\n",
    "\n",
    "    mem = get_mem_mib()\n",
    "    ttft = t_prefill + t_first\n",
    "    ttot = ttft + t_gen\n",
    "\n",
    "    # Throughput (GFLOPs/s)\n",
    "    pre_gflops   = to_gflops(FLOP_pre)\n",
    "    gen_gflops   = to_gflops(FLOP_gen)\n",
    "    tot_gflops   = to_gflops(FLOP_tot)\n",
    "    pre_gflops_s = throughput_gflops_per_s(pre_gflops, t_prefill)\n",
    "    gen_gflops_s = throughput_gflops_per_s(gen_gflops, t_gen)\n",
    "    tot_gflops_s = throughput_gflops_per_s(tot_gflops, ttot)\n",
    "\n",
    "    metrics = {\n",
    "        \"model\": \"vanilla\",\n",
    "        \"lens\": {\"S\": S, \"U_total\": U, \"H\": Htok, \"gen\": A, \"prompt\": L_prompt},\n",
    "        \"prefill_ms\": round(t_prefill*1000, 3),\n",
    "        \"first_token_ms\": round(t_first*1000, 3),\n",
    "        \"ttft_ms\": round(ttft*1000, 3),\n",
    "        \"gen_ms\": round(t_gen*1000, 3),\n",
    "        \"prefill_ms_per_tok\": round(1000 * t_prefill / L_prompt, 5),\n",
    "        \"gen_ms_per_tok\": round(1000 * t_gen / A, 5),\n",
    "        \"total_ms_per_tok\": round(1000 * ttot / (L_prompt + A), 5),\n",
    "        \"total_ms\": round(ttot*1000, 3),\n",
    "        \"peak_mem_alloc_MiB\": mem[\"alloc_MiB\"],\n",
    "        \"peak_mem_reserved_MiB\": mem[\"reserved_MiB\"],\n",
    "        # FLOPs/GFLOPs\n",
    "        \"FLOPs_prefill\": int(FLOP_pre), \"FLOPs_gen\": int(FLOP_gen), \"FLOPs_total\": int(FLOP_tot),\n",
    "        \"GFLOPs_prefill\": round(pre_gflops, 3), \"GFLOPs_gen\": round(gen_gflops, 3), \"GFLOPs_total\": round(tot_gflops, 3),\n",
    "        \"GFLOPs/s_prefill\": round(pre_gflops_s, 2), \"GFLOPs/s_gen\": round(gen_gflops_s, 2), \"GFLOPs/s_total\": round(tot_gflops_s, 2),\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "@torch.inference_mode()\n",
    "def profile_tri(model, S_ids, Utotal_ids, H_ids, lower_k, gen_len, greedily=True):\n",
    "    S = int(S_ids.size(1)); U = int(Utotal_ids.size(1)); Htok = int(H_ids.size(1)); A = int(gen_len)\n",
    "    L_prompt = S + U + Htok\n",
    "\n",
    "    # FLOPs 이론값(어텐션 기준)\n",
    "    FLOP_pre, FLOP_gen, FLOP_tot = flops_tri_attention(model, S, U, Htok, A, K=lower_k)\n",
    "\n",
    "    reset_peak(); sync(); t0 = time.perf_counter()\n",
    "    pkv, S_len, U_len = model.tri_build_caches(system_ids=S_ids, user_ids=Utotal_ids, lower_k=lower_k)\n",
    "    out = model.tri_step_logits(H_ids, lower_k, pkv, S_len, U_len, logits_to_keep=1, labels=None, write_cache=True)\n",
    "    sync(); t_prefill = time.perf_counter() - t0\n",
    "\n",
    "    logits = out.logits[:, -1, :]\n",
    "    if greedily:\n",
    "        cur = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "    else:\n",
    "        probs = F.softmax(logits, dim=-1); cur = torch.multinomial(probs, num_samples=1)\n",
    "\n",
    "    sync(); t1 = time.perf_counter()\n",
    "    out = model.tri_step_logits(cur, lower_k, pkv, S_len, U_len, logits_to_keep=1, labels=None, write_cache=True)\n",
    "    sync(); t_first = time.perf_counter() - t1\n",
    "\n",
    "    sync(); tg0 = time.perf_counter()\n",
    "    for _ in range(gen_len - 1):\n",
    "        out = model.tri_step_logits(cur, lower_k, pkv, S_len, U_len, logits_to_keep=1, labels=None, write_cache=True)\n",
    "        logits = out.logits[:, -1, :]\n",
    "        if greedily:\n",
    "            cur = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "        else:\n",
    "            probs = F.softmax(logits, dim=-1); cur = torch.multinomial(probs, num_samples=1)\n",
    "    sync(); t_gen = time.perf_counter() - tg0\n",
    "\n",
    "    mem = get_mem_mib()\n",
    "    ttft = t_prefill + t_first\n",
    "    ttot = ttft + t_gen\n",
    "\n",
    "    pre_gflops   = to_gflops(FLOP_pre)\n",
    "    gen_gflops   = to_gflops(FLOP_gen)\n",
    "    tot_gflops   = to_gflops(FLOP_tot)\n",
    "    pre_gflops_s = throughput_gflops_per_s(pre_gflops, t_prefill)\n",
    "    gen_gflops_s = throughput_gflops_per_s(gen_gflops, t_gen)\n",
    "    tot_gflops_s = throughput_gflops_per_s(tot_gflops, ttot)\n",
    "\n",
    "    metrics = {\n",
    "        \"model\": f\"LoPA-TRI(K={lower_k})\",\n",
    "        \"lens\": {\"S\": S, \"U_total\": U, \"H\": Htok, \"gen\": A, \"prompt\": L_prompt},\n",
    "        \"prefill_ms\": round(t_prefill*1000, 3),\n",
    "        \"first_token_ms\": round(t_first*1000, 3),\n",
    "        \"ttft_ms\": round(ttft*1000, 3),\n",
    "        \"gen_ms\": round(t_gen*1000, 3),\n",
    "        \"prefill_ms_per_tok\": round(1000 * t_prefill / L_prompt, 5),\n",
    "        \"gen_ms_per_tok\": round(1000 * t_gen / A, 5),\n",
    "        \"total_ms_per_tok\": round(1000 * ttot / (L_prompt + A), 5),\n",
    "        \"total_ms\": round(ttot*1000, 3),\n",
    "        \"peak_mem_alloc_MiB\": mem[\"alloc_MiB\"],\n",
    "        \"peak_mem_reserved_MiB\": mem[\"reserved_MiB\"],\n",
    "        # FLOPs/GFLOPs\n",
    "        \"FLOPs_prefill\": int(FLOP_pre), \"FLOPs_gen\": int(FLOP_gen), \"FLOPs_total\": int(FLOP_tot),\n",
    "        \"GFLOPs_prefill\": round(pre_gflops, 3), \"GFLOPs_gen\": round(gen_gflops, 3), \"GFLOPs_total\": round(tot_gflops, 3),\n",
    "        \"GFLOPs/s_prefill\": round(pre_gflops_s, 2), \"GFLOPs/s_gen\": round(gen_gflops_s, 2), \"GFLOPs/s_total\": round(tot_gflops_s, 2),\n",
    "    }\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c068e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Prompt(S/U/H)</th>\n",
       "      <th>GenToks</th>\n",
       "      <th>Prefill (ms)</th>\n",
       "      <th>FirstTok (ms)</th>\n",
       "      <th>TTFT (ms)</th>\n",
       "      <th>Gen (ms)</th>\n",
       "      <th>Prefill (ms/tok)</th>\n",
       "      <th>Gen (ms/tok)</th>\n",
       "      <th>Total (ms/tok)</th>\n",
       "      <th>Total (ms)</th>\n",
       "      <th>Peak alloc (MiB)</th>\n",
       "      <th>Peak reserved (MiB)</th>\n",
       "      <th>GFLOPs Prefill (theory)</th>\n",
       "      <th>GFLOPs/s Prefill</th>\n",
       "      <th>GFLOPs Gen (theory)</th>\n",
       "      <th>GFLOPs/s Gen</th>\n",
       "      <th>GFLOPs Total (theory)</th>\n",
       "      <th>GFLOPs/s Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>256/10496/4</td>\n",
       "      <td>512</td>\n",
       "      <td>830.868</td>\n",
       "      <td>18.556</td>\n",
       "      <td>849.424</td>\n",
       "      <td>9030.420</td>\n",
       "      <td>0.07725</td>\n",
       "      <td>17.63754</td>\n",
       "      <td>0.87681</td>\n",
       "      <td>9879.844</td>\n",
       "      <td>34741.07</td>\n",
       "      <td>96564.0</td>\n",
       "      <td>60655.684</td>\n",
       "      <td>73002.80</td>\n",
       "      <td>2955.877</td>\n",
       "      <td>327.32</td>\n",
       "      <td>63611.561</td>\n",
       "      <td>6438.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LoPA-TRI(K=8)</td>\n",
       "      <td>256/10496/4</td>\n",
       "      <td>512</td>\n",
       "      <td>278.757</td>\n",
       "      <td>22.794</td>\n",
       "      <td>301.551</td>\n",
       "      <td>11745.232</td>\n",
       "      <td>0.02592</td>\n",
       "      <td>22.93991</td>\n",
       "      <td>1.06911</td>\n",
       "      <td>12046.782</td>\n",
       "      <td>33262.51</td>\n",
       "      <td>96562.0</td>\n",
       "      <td>15190.502</td>\n",
       "      <td>54493.66</td>\n",
       "      <td>842.753</td>\n",
       "      <td>71.75</td>\n",
       "      <td>16033.256</td>\n",
       "      <td>1330.92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model Prompt(S/U/H)  GenToks  Prefill (ms)  FirstTok (ms)  \\\n",
       "0        vanilla   256/10496/4      512       830.868         18.556   \n",
       "1  LoPA-TRI(K=8)   256/10496/4      512       278.757         22.794   \n",
       "\n",
       "   TTFT (ms)   Gen (ms)  Prefill (ms/tok)  Gen (ms/tok)  Total (ms/tok)  \\\n",
       "0    849.424   9030.420           0.07725      17.63754         0.87681   \n",
       "1    301.551  11745.232           0.02592      22.93991         1.06911   \n",
       "\n",
       "   Total (ms)  Peak alloc (MiB)  Peak reserved (MiB)  GFLOPs Prefill (theory)  \\\n",
       "0    9879.844          34741.07              96564.0                60655.684   \n",
       "1   12046.782          33262.51              96562.0                15190.502   \n",
       "\n",
       "   GFLOPs/s Prefill  GFLOPs Gen (theory)  GFLOPs/s Gen  GFLOPs Total (theory)  \\\n",
       "0          73002.80             2955.877        327.32              63611.561   \n",
       "1          54493.66              842.753         71.75              16033.256   \n",
       "\n",
       "   GFLOPs/s Total  \n",
       "0         6438.52  \n",
       "1         1330.92  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 워밍업\n",
    "_ = profile_vanilla(van_model, S_ids[:, :64], Utotal_ids[:, :128], H_ids[:, :2], gen_len=32, greedily=True)\n",
    "_ = profile_tri(tri_model, S_ids[:, :64], Utotal_ids[:, :128], H_ids[:, :2], lower_k=LOWER_K, gen_len=32, greedily=True)\n",
    "\n",
    "# 본측정\n",
    "m_van = profile_vanilla(van_model, S_ids, Utotal_ids, H_ids, gen_len=LEN_GEN, greedily=True)\n",
    "m_tri = profile_tri(tri_model, S_ids, Utotal_ids, H_ids, lower_k=LOWER_K, gen_len=LEN_GEN, greedily=True)\n",
    "\n",
    "import pandas as pd\n",
    "def _row(m):\n",
    "    return {\n",
    "        \"Model\": m[\"model\"],\n",
    "        \"Prompt(S/U/H)\": f'{m[\"lens\"][\"S\"]}/{m[\"lens\"][\"U_total\"]}/{m[\"lens\"][\"H\"]}',\n",
    "        \"GenToks\": m[\"lens\"][\"gen\"],\n",
    "        \"Prefill (ms)\": m[\"prefill_ms\"], \"FirstTok (ms)\": m[\"first_token_ms\"], \"TTFT (ms)\": m[\"ttft_ms\"], \"Gen (ms)\": m[\"gen_ms\"],\n",
    "        \"Prefill (ms/tok)\": m[\"prefill_ms_per_tok\"], \"Gen (ms/tok)\": m[\"gen_ms_per_tok\"], \"Total (ms/tok)\": m[\"total_ms_per_tok\"], \"Total (ms)\": m[\"total_ms\"],\n",
    "        \"Peak alloc (MiB)\": m[\"peak_mem_alloc_MiB\"], \"Peak reserved (MiB)\": m[\"peak_mem_reserved_MiB\"],\n",
    "        # FLOPs\n",
    "        \"GFLOPs Prefill (theory)\": m[\"GFLOPs_prefill\"], \"GFLOPs/s Prefill\": m[\"GFLOPs/s_prefill\"],\n",
    "        \"GFLOPs Gen (theory)\": m[\"GFLOPs_gen\"], \"GFLOPs/s Gen\": m[\"GFLOPs/s_gen\"],\n",
    "        \"GFLOPs Total (theory)\": m[\"GFLOPs_total\"], \"GFLOPs/s Total\": m[\"GFLOPs/s_total\"],\n",
    "    }\n",
    "\n",
    "df = pd.DataFrame([_row(m_van), _row(m_tri)])\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f1b5d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def profile_tri(model, S_ids, Utotal_ids, H_ids, lower_k=8, gen_len=LEN_GEN, greedily=True):\n",
    "    # Prefill: S/U_total\n",
    "    reset_peak(); sync(); t0 = time.perf_counter()\n",
    "    pkv, S_len, U_len = model.tri_build_caches(system_ids=S_ids, user_ids=Utotal_ids, lower_k=lower_k)\n",
    "    # Header 기록(+ start logits 1개만)\n",
    "    out = model.tri_step_logits(H_ids, lower_k, pkv, S_len, U_len, logits_to_keep=1, labels=None, write_cache=True)\n",
    "    sync(); t_prefill = time.perf_counter() - t0\n",
    "\n",
    "    # 첫 토큰\n",
    "    logits = out.logits[:, -1, :]\n",
    "    if greedily:\n",
    "        cur = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "    else:\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        cur = torch.multinomial(probs, num_samples=1)\n",
    "\n",
    "    sync(); t1 = time.perf_counter()\n",
    "    out = model.tri_step_logits(cur, lower_k, pkv, S_len, U_len, logits_to_keep=1, labels=None, write_cache=True)\n",
    "    sync(); t_first = time.perf_counter() - t1\n",
    "\n",
    "    # Generation loop\n",
    "    sync(); tg0 = time.perf_counter()\n",
    "    for _ in range(gen_len - 1):\n",
    "        out = model.tri_step_logits(cur, lower_k, pkv, S_len, U_len, logits_to_keep=1, labels=None, write_cache=True)\n",
    "        logits = out.logits[:, -1, :]\n",
    "        if greedily:\n",
    "            cur = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "        else:\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            cur = torch.multinomial(probs, num_samples=1)\n",
    "    sync(); t_gen = time.perf_counter() - tg0\n",
    "\n",
    "    mem = get_mem_mib()\n",
    "    L_prompt = S_ids.size(1) + Utotal_ids.size(1) + H_ids.size(1)\n",
    "\n",
    "    metrics = {\n",
    "        \"model\": f\"LoPA-TRI(K={lower_k})\",\n",
    "        \"lens\": {\"S\": S_ids.size(1), \"U_total\": Utotal_ids.size(1), \"H\": H_ids.size(1), \"gen\": gen_len, \"prompt\": L_prompt},\n",
    "        \"prefill_ms\": round(t_prefill*1000, 3),\n",
    "        \"first_token_ms\": round(t_first*1000, 3),\n",
    "        \"ttft_ms\": round((t_prefill + t_first)*1000, 3),\n",
    "        \"gen_ms\": round(t_gen*1000, 3),\n",
    "        \"prefill_ms_per_tok\": round(1000 * t_prefill / L_prompt, 5),\n",
    "        \"gen_ms_per_tok\": round(1000 * t_gen / gen_len, 5),\n",
    "        \"total_ms_per_tok\": round(1000 * (t_prefill + t_first + t_gen) / (L_prompt + gen_len), 5),\n",
    "        \"total_ms\": round((t_prefill + t_first + t_gen)*1000, 3),\n",
    "        \"peak_mem_alloc_MiB\": mem[\"alloc_MiB\"],\n",
    "        \"peak_mem_reserved_MiB\": mem[\"reserved_MiB\"],\n",
    "    }\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1139e28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'vanilla', 'lens': {'S': 256, 'U_total': 10496, 'H': 4, 'gen': 512, 'prompt': 10756}, 'prefill_ms': 830.267, 'first_token_ms': 18.328, 'ttft_ms': 848.595, 'gen_ms': 9041.353, 'prefill_ms_per_tok': 0.07719, 'gen_ms_per_tok': 17.65889, 'total_ms_per_tok': 0.8777, 'total_ms': 9889.948, 'peak_mem_alloc_MiB': 34741.07, 'peak_mem_reserved_MiB': 96564.0}\n",
      "{'model': 'LoPA-TRI(K=8)', 'lens': {'S': 256, 'U_total': 10496, 'H': 4, 'gen': 512, 'prompt': 10756}, 'prefill_ms': 279.043, 'first_token_ms': 22.784, 'ttft_ms': 301.827, 'gen_ms': 11811.404, 'prefill_ms_per_tok': 0.02594, 'gen_ms_per_tok': 23.06915, 'total_ms_per_tok': 1.07501, 'total_ms': 12113.231, 'peak_mem_alloc_MiB': 33262.51, 'peak_mem_reserved_MiB': 96562.0}\n"
     ]
    }
   ],
   "source": [
    "# 워밍업(커널/캐시 안정화): 각 1회 짧게\n",
    "_ = profile_vanilla(van_model, S_ids[:, :64], Utotal_ids[:, :128], H_ids[:, :2], gen_len=32)\n",
    "_ = profile_tri(tri_model, S_ids[:, :64], Utotal_ids[:, :128], H_ids[:, :2], lower_k=LOWER_K, gen_len=32)\n",
    "\n",
    "# 본측정 (정확히 512토큰 생성)\n",
    "m_van = profile_vanilla(van_model, S_ids, Utotal_ids, H_ids, gen_len=LEN_GEN, greedily=True)\n",
    "m_tri = profile_tri(tri_model, S_ids, Utotal_ids, H_ids, lower_k=LOWER_K, gen_len=LEN_GEN, greedily=True)\n",
    "\n",
    "print(m_van)\n",
    "print(m_tri)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcf636f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] merged LoRA into base (unloaded PEFT)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>lens</th>\n",
       "      <th>prefill_ms</th>\n",
       "      <th>first_token_ms</th>\n",
       "      <th>ttft_ms</th>\n",
       "      <th>gen_ms</th>\n",
       "      <th>prefill_ms_per_tok</th>\n",
       "      <th>gen_ms_per_tok</th>\n",
       "      <th>total_ms_per_tok</th>\n",
       "      <th>total_ms</th>\n",
       "      <th>peak_mem_alloc_MiB</th>\n",
       "      <th>peak_mem_reserved_MiB</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>{'S': 256, 'U_total': 10496, 'H': 4, 'gen': 51...</td>\n",
       "      <td>830.267</td>\n",
       "      <td>18.328</td>\n",
       "      <td>848.595</td>\n",
       "      <td>9041.353</td>\n",
       "      <td>0.07719</td>\n",
       "      <td>17.65889</td>\n",
       "      <td>0.87770</td>\n",
       "      <td>9889.948</td>\n",
       "      <td>34741.07</td>\n",
       "      <td>96564.0</td>\n",
       "      <td>vanilla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LoPA-TRI(K=8)</td>\n",
       "      <td>{'S': 256, 'U_total': 10496, 'H': 4, 'gen': 51...</td>\n",
       "      <td>279.043</td>\n",
       "      <td>22.784</td>\n",
       "      <td>301.827</td>\n",
       "      <td>11811.404</td>\n",
       "      <td>0.02594</td>\n",
       "      <td>23.06915</td>\n",
       "      <td>1.07501</td>\n",
       "      <td>12113.231</td>\n",
       "      <td>33262.51</td>\n",
       "      <td>96562.0</td>\n",
       "      <td>LoPA(before)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LoPA-TRI(K=8)</td>\n",
       "      <td>{'S': 256, 'U_total': 10496, 'H': 4, 'gen': 51...</td>\n",
       "      <td>182.177</td>\n",
       "      <td>15.669</td>\n",
       "      <td>197.846</td>\n",
       "      <td>8192.882</td>\n",
       "      <td>0.01694</td>\n",
       "      <td>16.00172</td>\n",
       "      <td>0.74465</td>\n",
       "      <td>8390.728</td>\n",
       "      <td>32197.51</td>\n",
       "      <td>96552.0</td>\n",
       "      <td>LoPA(merged)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model                                               lens  \\\n",
       "0        vanilla  {'S': 256, 'U_total': 10496, 'H': 4, 'gen': 51...   \n",
       "1  LoPA-TRI(K=8)  {'S': 256, 'U_total': 10496, 'H': 4, 'gen': 51...   \n",
       "2  LoPA-TRI(K=8)  {'S': 256, 'U_total': 10496, 'H': 4, 'gen': 51...   \n",
       "\n",
       "   prefill_ms  first_token_ms  ttft_ms     gen_ms  prefill_ms_per_tok  \\\n",
       "0     830.267          18.328  848.595   9041.353             0.07719   \n",
       "1     279.043          22.784  301.827  11811.404             0.02594   \n",
       "2     182.177          15.669  197.846   8192.882             0.01694   \n",
       "\n",
       "   gen_ms_per_tok  total_ms_per_tok   total_ms  peak_mem_alloc_MiB  \\\n",
       "0        17.65889           0.87770   9889.948            34741.07   \n",
       "1        23.06915           1.07501  12113.231            33262.51   \n",
       "2        16.00172           0.74465   8390.728            32197.51   \n",
       "\n",
       "   peak_mem_reserved_MiB          note  \n",
       "0                96564.0       vanilla  \n",
       "1                96562.0  LoPA(before)  \n",
       "2                96552.0  LoPA(merged)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# LoRA가 붙어 있으면 병합해서 언로드 (추론 속도 개선)\n",
    "try:\n",
    "    from peft import PeftModel\n",
    "    if isinstance(tri_model, PeftModel):\n",
    "        tri_model = tri_model.merge_and_unload()\n",
    "        tri_model = tri_model.to(device).eval()\n",
    "        print(\"[info] merged LoRA into base (unloaded PEFT)\")\n",
    "except Exception as e:\n",
    "    print(\"[info] LoRA merge skipped:\", e)\n",
    "\n",
    "# 동일 백엔드 재지정\n",
    "try:\n",
    "    tri_model.config._attn_implementation = ATTN_IMPL\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# 재측정\n",
    "m_tri2 = profile_tri(tri_model, S_ids, Utotal_ids, H_ids, lower_k=LOWER_K, gen_len=LEN_GEN, greedily=True)\n",
    "display(pd.DataFrame([m_van, m_tri, m_tri2]).assign(note=[\"vanilla\",\"LoPA(before)\",\"LoPA(merged)\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "294be00e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Prompt(S/U/H)</th>\n",
       "      <th>GenToks</th>\n",
       "      <th>Prefill (ms)</th>\n",
       "      <th>FirstTok (ms)</th>\n",
       "      <th>TTFT (ms)</th>\n",
       "      <th>Gen (ms)</th>\n",
       "      <th>Prefill (ms/tok)</th>\n",
       "      <th>Gen (ms/tok)</th>\n",
       "      <th>Total (ms/tok)</th>\n",
       "      <th>Total (ms)</th>\n",
       "      <th>Peak alloc (MiB)</th>\n",
       "      <th>Peak reserved (MiB)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>256/10496/4</td>\n",
       "      <td>512</td>\n",
       "      <td>830.267</td>\n",
       "      <td>18.328</td>\n",
       "      <td>848.595</td>\n",
       "      <td>9041.353</td>\n",
       "      <td>0.07719</td>\n",
       "      <td>17.65889</td>\n",
       "      <td>0.87770</td>\n",
       "      <td>9889.948</td>\n",
       "      <td>34741.07</td>\n",
       "      <td>96564.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LoPA-TRI(K=8)</td>\n",
       "      <td>256/10496/4</td>\n",
       "      <td>512</td>\n",
       "      <td>279.043</td>\n",
       "      <td>22.784</td>\n",
       "      <td>301.827</td>\n",
       "      <td>11811.404</td>\n",
       "      <td>0.02594</td>\n",
       "      <td>23.06915</td>\n",
       "      <td>1.07501</td>\n",
       "      <td>12113.231</td>\n",
       "      <td>33262.51</td>\n",
       "      <td>96562.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model Prompt(S/U/H)  GenToks  Prefill (ms)  FirstTok (ms)  \\\n",
       "0        vanilla   256/10496/4      512       830.267         18.328   \n",
       "1  LoPA-TRI(K=8)   256/10496/4      512       279.043         22.784   \n",
       "\n",
       "   TTFT (ms)   Gen (ms)  Prefill (ms/tok)  Gen (ms/tok)  Total (ms/tok)  \\\n",
       "0    848.595   9041.353           0.07719      17.65889         0.87770   \n",
       "1    301.827  11811.404           0.02594      23.06915         1.07501   \n",
       "\n",
       "   Total (ms)  Peak alloc (MiB)  Peak reserved (MiB)  \n",
       "0    9889.948          34741.07              96564.0  \n",
       "1   12113.231          33262.51              96562.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def to_row(m):\n",
    "    return {\n",
    "        \"Model\": m[\"model\"],\n",
    "        \"Prompt(S/U/H)\": f'{m[\"lens\"][\"S\"]}/{m[\"lens\"][\"U_total\"]}/{m[\"lens\"][\"H\"]}',\n",
    "        \"GenToks\": m[\"lens\"][\"gen\"],\n",
    "        \"Prefill (ms)\": m[\"prefill_ms\"],\n",
    "        \"FirstTok (ms)\": m[\"first_token_ms\"],\n",
    "        \"TTFT (ms)\": m[\"ttft_ms\"],\n",
    "        \"Gen (ms)\": m[\"gen_ms\"],\n",
    "        \"Prefill (ms/tok)\": m[\"prefill_ms_per_tok\"],\n",
    "        \"Gen (ms/tok)\": m[\"gen_ms_per_tok\"],\n",
    "        \"Total (ms/tok)\": m[\"total_ms_per_tok\"],\n",
    "        \"Total (ms)\": m[\"total_ms\"],\n",
    "        \"Peak alloc (MiB)\": m[\"peak_mem_alloc_MiB\"],\n",
    "        \"Peak reserved (MiB)\": m[\"peak_mem_reserved_MiB\"],\n",
    "    }\n",
    "\n",
    "df = pd.DataFrame([to_row(m_van), to_row(m_tri)])\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a318a44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ATTN HOOK] calls: {'fa2_calls': 328, 'mask_none': 328, 'mask_additive': 0}\n"
     ]
    }
   ],
   "source": [
    "# TRI 어텐션 fwd를 훅킹해서 어떤 경로/마스크가 쓰이는지 카운트\n",
    "from transformers.models.llama.modeling_llama import LlamaAttention\n",
    "\n",
    "_attn_calls = {\"fa2_calls\":0, \"mask_none\":0, \"mask_additive\":0}\n",
    "_orig_fwd = LlamaAttention.forward\n",
    "\n",
    "def _hook_fwd(self, hidden_states, position_embeddings, attention_mask,\n",
    "              past_key_values=None, cache_position=None, **kwargs):\n",
    "    impl = getattr(self.config, \"_attn_implementation\", \"eager\")\n",
    "    if impl == \"flash_attention_2\":\n",
    "        _attn_calls[\"fa2_calls\"] += 1\n",
    "    if attention_mask is None:\n",
    "        _attn_calls[\"mask_none\"] += 1\n",
    "    else:\n",
    "        _attn_calls[\"mask_additive\"] += 1\n",
    "    return _orig_fwd(self, hidden_states, position_embeddings, attention_mask,\n",
    "                     past_key_values=past_key_values, cache_position=cache_position, **kwargs)\n",
    "\n",
    "# 훅 설치\n",
    "LlamaAttention.forward = _hook_fwd\n",
    "\n",
    "# LoPA 한 번 짧게 돌려서 카운트\n",
    "_ = profile_tri(tri_model, S_ids[:, :64], Utotal_ids[:, :128], H_ids[:, :2], lower_k=LOWER_K, gen_len=8, greedily=True)\n",
    "print(\"[ATTN HOOK] calls:\", _attn_calls)\n",
    "\n",
    "# 사용 후 원복\n",
    "LlamaAttention.forward = _orig_fwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47be230",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
